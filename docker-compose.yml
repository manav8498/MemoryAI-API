# =============================================================================
# AI MEMORY API - DOCKER COMPOSE
# =============================================================================
# Complete stack with all dependencies for local development and testing

version: '3.8'

services:
  # ===========================================================================
  # APPLICATION
  # ===========================================================================
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: memory-api
    ports:
      - "8000:8000"
    environment:
      - APP_ENV=development
      - DEBUG=true
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_USER=memory_ai
      - POSTGRES_PASSWORD=memory_password
      - POSTGRES_DB=memory_ai_db
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - MILVUS_HOST=milvus
      - MILVUS_PORT=19530
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=memory_password
      - NEO4J_DATABASE=neo4j
    depends_on:
      - postgres
      - redis
      - milvus
      - neo4j
    volumes:
      - ./backend:/app/backend
      - ./logs:/app/logs
      - ./.env:/app/.env
    networks:
      - memory-network
    restart: unless-stopped

  # ===========================================================================
  # POSTGRESQL DATABASE
  # ===========================================================================
  postgres:
    image: postgres:16-alpine
    container_name: memory-postgres
    environment:
      - POSTGRES_USER=memory_ai
      - POSTGRES_PASSWORD=memory_password
      - POSTGRES_DB=memory_ai_db
    ports:
      - "5433:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - memory-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U memory_ai"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ===========================================================================
  # REDIS CACHE
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: memory-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - memory-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ===========================================================================
  # MILVUS VECTOR DATABASE
  # ===========================================================================
  milvus:
    image: milvusdb/milvus:v2.3.5
    container_name: memory-milvus
    command: milvus run standalone
    environment:
      - ETCD_ENDPOINTS=etcd:2379
      - MINIO_ADDRESS=minio:9000
      - MINIO_ACCESS_KEY=minioadmin
      - MINIO_SECRET_KEY=minioadmin
    ports:
      - "19530:19530"
      - "9091:9091"
    depends_on:
      - etcd
      - minio
    volumes:
      - milvus-data:/var/lib/milvus
    networks:
      - memory-network
    restart: unless-stopped

  # Milvus dependencies
  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: memory-etcd
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - etcd-data:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    networks:
      - memory-network

  minio:
    image: minio/minio:RELEASE.2023-11-01T01-57-10Z
    container_name: memory-minio
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    volumes:
      - minio-data:/minio_data
    command: minio server /minio_data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    networks:
      - memory-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  # ===========================================================================
  # NEO4J KNOWLEDGE GRAPH
  # ===========================================================================
  neo4j:
    image: neo4j:5.16.0
    container_name: memory-neo4j
    environment:
      - NEO4J_AUTH=neo4j/memory_password
      - NEO4J_dbms_memory_heap_max__size=2G
      - NEO4J_dbms_memory_pagecache_size=1G
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
    networks:
      - memory-network
    healthcheck:
      test: ["CMD-SHELL", "cypher-shell -u neo4j -p memory_password 'RETURN 1'"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  # ===========================================================================
  # KAFKA (OPTIONAL - for RL trajectory streaming)
  # ===========================================================================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: memory-kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    depends_on:
      - zookeeper
    networks:
      - memory-network

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: memory-zookeeper
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
      - ZOOKEEPER_TICK_TIME=2000
    networks:
      - memory-network

  # ===========================================================================
  # OBSERVABILITY
  # ===========================================================================
  # Prometheus for metrics
  prometheus:
    image: prom/prometheus:latest
    container_name: memory-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./observability/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    networks:
      - memory-network

  # Grafana for dashboards
  grafana:
    image: grafana/grafana:latest
    container_name: memory-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - memory-network

# =============================================================================
# NETWORKS
# =============================================================================
networks:
  memory-network:
    driver: bridge

# =============================================================================
# VOLUMES
# =============================================================================
volumes:
  postgres-data:
  redis-data:
  milvus-data:
  etcd-data:
  minio-data:
  neo4j-data:
  neo4j-logs:
  prometheus-data:
  grafana-data:
